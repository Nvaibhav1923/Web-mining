{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2021-12-16T04:55:25.986719Z","iopub.execute_input":"2021-12-16T04:55:25.987175Z","iopub.status.idle":"2021-12-16T04:56:12.572368Z","shell.execute_reply.started":"2021-12-16T04:55:25.987130Z","shell.execute_reply":"2021-12-16T04:56:12.571392Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# dataset :https://www.kaggle.com/sharvan123/kmeans-data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pyspark\nsc = pyspark.SparkContext(appName=\"intro_to_spark\")\n\nlog_of_songs = [\n        \"Despacito\",\n        \"Nice for what\",\n        \"No tears left to cry\",\n        \"Despacito\",\n        \"Havana\",\n        \"In my feelings\",\n        \"Nice for what\",\n        \"despacito\",\n        \"All the stars\"\n]\n\n# parallelize the log_of_songs to use with Spark\ndistributed_song_log = sc.parallelize(log_of_songs)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-16T04:56:18.787179Z","iopub.execute_input":"2021-12-16T04:56:18.787455Z","iopub.status.idle":"2021-12-16T04:56:23.752308Z","shell.execute_reply.started":"2021-12-16T04:56:18.787428Z","shell.execute_reply":"2021-12-16T04:56:23.750480Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = sc.textFile(\"data/mllib/kmeans_data.txt\")\nparsedData = data.map(lambda line: array([float(x) for x in line.split(' ')]))\n# gmm = GaussianMixture.train(parsedData, 2)\nclusters = KMeans.train(parsedData, 2)\n\n# Evaluate clustering by computing Within Set Sum of Squared Errors\n# def error(point):\n#     center = clusters.centers[clusters.predict(point)]\n#     return sqrt(sum([x**2 for x in (point - center)]))\n\n# WSSSE = parsedData.map(lambda point: error(point)).reduce(lambda x, y: x + y)\n# print(\"Within Set Sum of Squared Error = \" + str(WSSSE))\n\n# # Save and load model\n# clusters.save(sc, \"target/org/apache/spark/PythonKMeansExample/KMeansModel\")\n# sameModel = KMeansModel.load(sc, \"target/org/apache/spark/PythonKMeansExample/KMeansModel\")","metadata":{"execution":{"iopub.status.busy":"2021-12-16T04:53:24.065483Z","iopub.status.idle":"2021-12-16T04:53:24.065799Z","shell.execute_reply.started":"2021-12-16T04:53:24.065626Z","shell.execute_reply":"2021-12-16T04:53:24.065641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = spark.read.text(data)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T04:53:24.066652Z","iopub.status.idle":"2021-12-16T04:53:24.066990Z","shell.execute_reply.started":"2021-12-16T04:53:24.066830Z","shell.execute_reply":"2021-12-16T04:53:24.066847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = data.toDF()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T04:53:24.068371Z","iopub.status.idle":"2021-12-16T04:53:24.068684Z","shell.execute_reply.started":"2021-12-16T04:53:24.068524Z","shell.execute_reply":"2021-12-16T04:53:24.068540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import array\nfrom math import sqrt\n\nfrom pyspark.mllib.clustering import KMeans, KMeansModel\n\n# Load and parse the data\ndata = sc.textFile(\"../input/kmeans-data/kmeans_data.txt\")\nparsedData = data.map(lambda line: array([float(x) for x in line.split(' ')]))\nprint(parsedData)\n# Build the model (cluster the data)\nclusters = KMeans.train(parsedData, 2, maxIterations=10, initializationMode=\"random\")\nprediction = clusters.predict([5.0,9.0,8.0])\n# maped_prediction = prediction.map(lambda x: x in x)\nprediction\n\n# Evaluate clustering by computing Within Set Sum of Squared Errors\ndef error(point):\n    center = clusters.centers[clusters.predict(point)]\n    return sqrt(sum([x**2 for x in (point - center)]))\n\nWSSSE = parsedData.map(lambda point: error(point)).reduce(lambda x, y: x + y)\nprint(\"Within Set Sum of Squared Error = \" + str(WSSSE))\n\n# Save and load model\n# clusters.save(sc, \"target/org/apache/spark/PythonKMeansExample/KMeansModel\")\n# sameModel = KMeansModel.load(sc, \"target/org/apache/spark/PythonKMeansExample/KMeansModel\")","metadata":{"execution":{"iopub.status.busy":"2021-12-16T04:56:30.892973Z","iopub.execute_input":"2021-12-16T04:56:30.893773Z","iopub.status.idle":"2021-12-16T04:56:34.303288Z","shell.execute_reply.started":"2021-12-16T04:56:30.893724Z","shell.execute_reply":"2021-12-16T04:56:34.302444Z"},"trusted":true},"execution_count":4,"outputs":[]}]}